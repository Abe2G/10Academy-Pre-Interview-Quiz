{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate goal is to minimize student frustration and satisfaction and to most effectively use limited coaching resources. Cancelling early may be one indication of frustration or low satisfaction and the more students enrolled in the course who do not make at least one payment, much less finish the course, the less coaching resources are being used effectively. \n",
    "With this in mind, in order to consider launching the experiment either of the following must be observed:\n",
    "<ul type='square'><li>Increased retention (more students staying beyond the free trial in the experiment group)</li>\n",
    "<li>Decreased Gross Conversion coupled to increased Net Conversion (less students enrolling in the free trial but more students staying beyond the free trial)</li></ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Total of 37 days experment and control data observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing value columns: Enrollment and Payment\n",
    "<ul><li>Enrollment:14 and Payment: 14 for Control</li>\n",
    "    <li>Enrollment:14 and Payment: 14 for Experment</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessment of the statistical significance of an A/B test is dependent on what kind of probability distribution the experimental data follows. Given your answer above, which statistical tests are appropriate to use for this project?<br>\n",
    "<b>Answer</b><br>\n",
    "probability distribution for our control group is binomial because the we have only  two possible outcomes eaither retainion or leaving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In frequentist analysis, mostly used for A/B testing, we use p-values to measure the significance of the experimental feature over the null hypothesis (the hypothesis that the new feature does not have an impact). How are p-values computed? What information do p-values provide? Are you familiar with type-I and type-II errors? Can you comment to which error types p-values are related?\n",
    " \n",
    " Type I error is the false rejection of the null hypothesis and type II error is the false acceptance of the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the number of data points in the experiment enough to make a reasonable judgement or should Udacity run a longer experiment? Remember that running the experiment longer may be costly for many reasons, so you should always optimize the number of samples to make a statistically sound decision.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does your A/B testing analysis tells you? Does the experimental feature improve Enrollment, the target variable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a analyst desires a higher power, bigger sample sizes are needed. However, compaies with less customer may cost more to collect enough sample due to elongated data collection. There are online sample size calculators such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we collected these estimates, we should estimate the standard deviation of a metric, this is computed for sample size calculations and confidence intervals for our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pageviews in control: 345543\n",
      "number of Pageviewsin experiment: 344660\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import math as mt\n",
    "from scipy.stats import norm\n",
    "\n",
    "DATA_DIR='data/'\n",
    "# Load Excel dataset for analysis. I will use pandas library to work with it.\n",
    "def load_data(file_name,sheet):\n",
    "    return pd.read_excel(os.path.join(DATA_DIR,file_name), sheet, index_col=None)\n",
    "\n",
    "#Inputs: required alpha value (alpha should already fit the required test)\n",
    "#Returns: z-score for given alpha\n",
    "def get_z_score(alpha):\n",
    "    return norm.ppf(alpha)\n",
    "\n",
    "# Inputs p-baseline conversion rate which is our estimated p and d-minimum detectable change\n",
    "# Returns\n",
    "def get_sds(p,d):\n",
    "    sd1=mt.sqrt(2*p*(1-p))\n",
    "    sd2=mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n",
    "    sds=[sd1,sd2]\n",
    "    return sds\n",
    "\n",
    "# Inputs:sd1-sd for the baseline,sd2-sd for the expected change,alpha,beta,d-d_min,p-baseline estimate p\n",
    "# Returns: the minimum sample size required per group according to metric denominator\n",
    "def get_sampSize(sds,alpha,beta,d):\n",
    "    n=pow((get_z_score(1-alpha/2)*sds[0]+get_z_score(1-beta)*sds[1]),2)/pow(d,2)\n",
    "    return n\n",
    "\n",
    "control=load_data('UdacityABtesting.xlsx','Control')\n",
    "experiment=load_data('UdacityABtesting.xlsx','Experiment')\n",
    "\n",
    "pageviews_cont=control['Pageviews'].sum()\n",
    "pageviews_exp=experiment['Pageviews'].sum()\n",
    "pageviews_total=pageviews_cont+pageviews_exp\n",
    "print (\"number of pageviews in control:\", pageviews_cont)\n",
    "print (\"number of Pageviewsin experiment:\" ,pageviews_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4988 and 0.5012 ; Is 0.5006 inside this range?\n"
     ]
    }
   ],
   "source": [
    "p=0.5\n",
    "alpha=0.05\n",
    "p_hat=round(pageviews_cont/(pageviews_total),4)\n",
    "sd=mt.sqrt(p*(1-p)/(pageviews_total))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4959 and 0.5041 ; Is 0.5005 inside this range?\n"
     ]
    }
   ],
   "source": [
    "clicks_cont=control['Clicks'].sum()\n",
    "clicks_exp=experiment['Clicks'].sum()\n",
    "clicks_total=clicks_cont+clicks_exp\n",
    "\n",
    "p_hat=round(clicks_cont/clicks_total,4)\n",
    "sd=mt.sqrt(p*(1-p)/clicks_total)\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between -0.0013 and 0.0013 ; Is 0.0001 within this range?\n"
     ]
    }
   ],
   "source": [
    "ctp_cont=clicks_cont/pageviews_cont\n",
    "ctp_exp=clicks_exp/pageviews_exp\n",
    "d_hat=round(ctp_exp-ctp_cont,4)\n",
    "p_pooled=clicks_total/pageviews_total\n",
    "sd_pooled=mt.sqrt(p_pooled*(1-p_pooled)*(1/pageviews_cont+1/pageviews_exp))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd_pooled,4)\n",
    "print (\"The confidence interval is between\",0-ME,\"and\",0+ME,\"; Is\",d_hat,\"within this range?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total clicks from complete records only\n",
    "clicks_cont=control[\"Clicks\"].loc[control[\"Enrollments\"].notnull()].sum()\n",
    "clicks_exp=experiment[\"Clicks\"].loc[experiment[\"Enrollments\"].notnull()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not completed ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
